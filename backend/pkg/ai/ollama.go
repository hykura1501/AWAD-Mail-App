package ai

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
)

// OllamaService implements SummarizerService using Ollama local LLM
type OllamaService struct {
	BaseURL string // e.g., "http://localhost:11434"
	Model   string // e.g., "llama3", "mistral", "qwen2"
}

// NewOllamaService creates a new Ollama service
func NewOllamaService(baseURL, model string) *OllamaService {
	if baseURL == "" {
		baseURL = "http://localhost:11434"
	}
	if model == "" {
		model = "llama3"
	}
	return &OllamaService{
		BaseURL: baseURL,
		Model:   model,
	}
}

// SummarizeEmail implements SummarizerService
func (o *OllamaService) SummarizeEmail(ctx context.Context, emailText string) (string, error) {
	url := o.BaseURL + "/api/generate"

	// Enhanced Vietnamese prompt with professional prompting techniques
	// (Same as Gemini for consistency across providers)
	prompt := fmt.Sprintf(`B·∫°n l√† tr·ª£ l√Ω email th√¥ng minh. Ph√¢n t√≠ch email sau v√† t·∫°o t√≥m t·∫Øt H·ªÆU √çCH gi√∫p user quy·∫øt ƒë·ªãnh nhanh.

H∆Ø·ªöNG D·∫™N:
- D√≤ng 1: T√≥m t·∫Øt √Ω ch√≠nh trong 1 c√¢u ng·∫Øn g·ªçn
- D√≤ng 2 (n·∫øu c√≥): "üìå C·∫ßn l√†m: [action item]" ho·∫∑c "üìÖ Deadline: [th·ªùi gian]" ho·∫∑c "üí° L∆∞u √Ω: [ƒëi·ªÉm quan tr·ªçng]"
- N·∫øu email qu·∫£ng c√°o/spam: ch·ªâ ghi "Qu·∫£ng c√°o t·ª´ [t√™n c√¥ng ty]"
- Ng√¥n ng·ªØ: Ti·∫øng Vi·ªát, t·ªëi ƒëa 2 d√≤ng

V√ç D·ª§ OUTPUT T·ªêT:
"Cu·ªôc h·ªçp team v√†o th·ª© 5 l√∫c 14h v·ªÅ ti·∫øn ƒë·ªô d·ª± √°n ABC.
üìå C·∫ßn l√†m: Chu·∫©n b·ªã b√°o c√°o ti·∫øn ƒë·ªô tr∆∞·ªõc th·ª© 4."

EMAIL:
%s

T√ìM T·∫ÆT:`, emailText)

	payload := map[string]interface{}{
		"model":  o.Model,
		"prompt": prompt,
		"stream": false,
		"options": map[string]interface{}{
			"temperature": 0.3,
			"num_predict": 100, // Shorter output
		},
	}

	body, err := json.Marshal(payload)
	if err != nil {
		return "", fmt.Errorf("failed to marshal request: %w", err)
	}

	req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(body))
	if err != nil {
		return "", err
	}
	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return "", fmt.Errorf("ollama request failed: %w", err)
	}
	defer resp.Body.Close()

	respBody, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", fmt.Errorf("failed to read response: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("ollama API error (%d): %s", resp.StatusCode, string(respBody))
	}

	var result struct {
		Response string `json:"response"`
		Done     bool   `json:"done"`
	}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return "", fmt.Errorf("failed to parse response: %w", err)
	}

	return result.Response, nil
}
